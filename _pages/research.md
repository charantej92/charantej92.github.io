---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
classes: wide
---

### Fourier Analysis
{: style="font-size:1.2em; color: #7a8288;"}
---

 The significance and prevalence of the FFT algorithm cannot be emphasized enough. As datasets continue to grow in size, there is a demand to lower the complexity below the traditional FFT's $O(N \log N)$ bound. A crucial aspect is to recognize and leverage scenarios that impact the DFT coefficients. With this in consideration, I pose the following inquiry:

"Which structures on the frequency support, of size $k$, allow for a computational complexity of $O(k\log k)$?" ([details](https://arxiv.org/abs/2211.15299))
        
#### Publications on Fourier Analysis
{: style="font-size:1.0em;"}

- *Fast DFT Computation for Signals with Structured Support*  Charantej Reddy P, Aditya Siripuram, Brad Osgood
arXiv preprint [arXiv:2211.15299](https://arxiv.org/abs/2211.15299) (2022).
- *Computing the Discrete Fourier Transform of signals with spectral frequency support*  PC Reddy, VSSP Tej, A Siripuram, B Osgood
2021 IEEE International Symposium on Information Theory (ISIT), 2381-2386 ([online](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9518104))
- *Fast DFT computation for signals with spectral support* PC Reddy, VSSP Tej, A Siripuram
2021 National Conference on Communications (NCC), 1-6 ([online](https://ieeexplore.ieee.org/document/9530137))
- Some results on convolution idempotents* PC Reddy, A Siripuram, B Osgood
2020 IEEE International Symposium on Information Theory (ISIT), 1462-1467 ([online](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174204))

### Adversarial Machine Learning
{: style="font-size:1.2em; color: #7a8288;"}
---

The phenomenon of carefully crafted imperceptible perturbations causing misclassification in state-of-the-art deep learning models is widely acknowledged. Analyzing and comprehending these adversarial perturbations is vital for developing robust convolutional neural networks. However, their underlying mechanisms remain insufficiently understood. I am currently exploring the following question:

"Is there any relationship between the imperceptibility and semantic significance of adversarial perturbations?" In other words, "can adversarial perturbations change only the regions of the image that are important for classification, while still being imperceptible?" ([details](https://ieeexplore.ieee.org/abstract/document/10073613))

## Publications on Machine Learning
{: style="font-size:1.0em;"}
- *Can Perceptual Guidance Lead to Semantically Explainable Adversarial Perturbations?* Charantej Reddy Pochimireddy, Aditya T. Siripuram, and Sumohana S. Channappayya
IEEE Journal of Selected Topics in Signal Processing (2023), 1-11 ([online](https://ieeexplore.ieee.org/abstract/document/10073613))

## Other work (including collaborations)
{: style="font-size:1.0em;"}
- *A survey of signal processing based graph learning techniques* B Subbareddy, P Charantej Reddy, Aditya Siripuram, and Jingxin Zhang
2019 1st International Conference on Industrial Artificial Intelligence (IAI). IEEE. 2019, 1-6 ([online](https://ieeexplore.ieee.org/document/8850827))